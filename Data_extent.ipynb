{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f7b85c-2d2d-471b-9574-d2cd18da70ed",
   "metadata": {},
   "source": [
    "# Code to reprocessing reanalysis datasets used in Aguayo et al. (in review)\n",
    "Developed by Rodrigo Aguayo (2020-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3def55cf-78b3-4ef0-bb10-fd8b69ec3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import rioxarray as rioxr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir('/home/rooda/Dropbox/Patagonia/Data/') \n",
    "local  = \"/media/rooda/Local Disk/Datasets\"\n",
    "days = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "\n",
    "encode_pp  = {\"pp\": {\"zlib\": True, \"complevel\": 9, \"dtype\": \"int16\"}}\n",
    "encode_t2m = {\"t2m\": {\"zlib\": True, \"complevel\": 9, \"dtype\": \"float32\"}}\n",
    "mask       = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/dem_mask.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38827e-9d9d-40f2-a714-da4ee799303e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce657a4-e1ac-44e1-a08f-2e621f8ff451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pp  = {'tp':'pp', 'longitude':'lon', 'latitude':'lat'} # monthly averaged reanalysis (ok)\n",
    "stack_pp = xr.open_dataset(os.path.join(local + \"/ERA5/Monthly/ERA5_1959_2021m.nc\"), chunks =\"auto\").rename(dict_pp)[\"pp\"]\n",
    "stack_pp = stack_pp.where((stack_pp.lon >= -76) & (stack_pp.lon <= -65) & (stack_pp.lat >= -56) & (stack_pp.lat <= -40), drop=True)\n",
    "months  = xr.DataArray(days.repeat(2021-1959+1), coords=[stack_pp.time], name='month_length')\n",
    "stack_pp = (stack_pp*months*1000).round(0)\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_ERA5_1959_2021m.nc\")\n",
    "\n",
    "dict_t2m  = {'longitude':'lon', 'latitude':'lat'} # monthly averaged reanalysis (ok)\n",
    "stack_t2m = xr.open_dataset(os.path.join(local + \"/ERA5/Monthly/ERA5_1959_2021m.nc\"), chunks =\"auto\").rename(dict_t2m)[\"t2m\"]\n",
    "stack_t2m = stack_t2m.where((stack_t2m.lon >= -76) & (stack_t2m.lon <= -65) & (stack_t2m.lat >= -56) & (stack_t2m.lat <= -40), drop=True)\n",
    "stack_t2m = (stack_t2m-273.15).round(2)\n",
    "stack_t2m.to_netcdf(\"Temperature/T2M_ERA5_1959_2021m.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43c212-1238-4bfa-be03-d775a0bb512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reanalysis 3-hourly data\n",
    "dict_pp   = {'tp':'pp', 'longitude':'lon', 'latitude':'lat'}\n",
    "stack_pp  = xr.open_mfdataset(os.path.join(local + \"/ERA5/Hourly/ERA5*.nc\"), concat_dim='time', combine='nested', chunks =\"auto\").rename(dict_pp)[\"pp\"]  \n",
    "mask_pp   = regionmask.mask_geopandas(mask, stack_pp)\n",
    "stack_pp  = stack_pp.where(mask_pp >= 0, drop=True)\n",
    "stack_pp  = stack_pp.sortby(\"time\").resample(time='1D').sum(skipna=False)\n",
    "stack_pp  = (stack_pp*3*1000).round(0)\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_ERA5_1959_2021d.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927dc03-093c-4e77-8f19-041d56829924",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_t2m   = {'longitude':'lon', 'latitude':'lat'}\n",
    "stack_t2m  = xr.open_mfdataset(os.path.join(local + \"/ERA5/Hourly/ERA5*.nc\"), concat_dim='time', combine='nested', chunks =\"auto\").rename(dict_t2m)[\"t2m\"] \n",
    "mask_t2m   = regionmask.mask_geopandas(mask, stack_t2m)\n",
    "stack_t2m  = stack_t2m.where(mask_t2m >= 0, drop=True)\n",
    "stack_t2m_max = stack_t2m.sortby(\"time\").resample(time='1D').max()\n",
    "stack_t2m_min = stack_t2m.sortby(\"time\").resample(time='1D').min()\n",
    "stack_t2m_max = (stack_t2m_max-273.15).round(2)\n",
    "stack_t2m_min = (stack_t2m_min-273.15).round(2)\n",
    "stack_t2m_max.to_netcdf(\"Temperature/Tmax_ERA5_1959_2021d.nc\")\n",
    "stack_t2m_min.to_netcdf(\"Temperature/Tmin_ERA5_1959_2021d.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ff16a-94bf-4775-8ba0-e4e1b06ad4eb",
   "metadata": {},
   "source": [
    "## ERA5-LAND\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7be2f5-b516-4f55-b8ac-0439f5541399",
   "metadata": {},
   "outputs": [],
   "source": [
    " # monthly averaged reanalysis\n",
    "dict_pp   = {'tp':'pp', 'longitude':'lon', 'latitude':'lat'}\n",
    "stack_pp  = xr.open_dataset(os.path.join(local + \"/ERA5_LAND/Monthly/PP_ERA5L_1950_2021m.nc\"), chunks =\"auto\").rename(dict_pp)  \n",
    "stack_pp  = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "stack_pp  = (stack_pp*1000).astype(\"int32\")\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_ERA5L_1950_2021m.nc\")\n",
    "\n",
    "dict_t2m  = {'longitude':'lon', 'latitude':'lat'}\n",
    "stack_t2m = xr.open_dataset(os.path.join(local, \"/ERA5_LAND/Monthly/T2M_ERA5L_1950_2021m.nc\"), chunks =\"auto\").rename(dict_t2m)  \n",
    "stack_t2m = stack_t2m.where((stack_t2m.lon >= -79) & (stack_t2m.lon <= -64) & (stack_t2m.lat >= -57) & (stack_t2m.lat <= -40), drop=True)\n",
    "stack_t2m = (stack_t2m-273.15).round(2)\n",
    "stack_t2m.to_netcdf(\"Temperature/T2M_ERA5__1950_2021m.nc\")\n",
    "\n",
    " # reanalysis 3-hourly data\n",
    "stack_pp  = xr.open_mfdataset(os.path.join(local + \"/ERA5_LAND/Hourly/PP_ERA5L_*.nc\"), concat_dim='time', combine='nested', chunks =\"auto\")*1000     \n",
    "stack_pp  = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "stack_pp  = stack_pp.resample(time='1D').mean()\n",
    "stack_pp  = (stack_pp*1000).round(1)\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_ERA5L_1950_2021d.nc\")\n",
    "\n",
    "stack_t2m  = xr.open_mfdataset(os.path.join(local + \"/ERA5_LAND/Hourly/T2M_ERA5L.*.nc\"), concat_dim='time', combine='nested', chunks =\"auto\")-273.15\n",
    "stack_t2m  = stack_t2m.where((stack_t2m.lon >= -79) & (stack_t2m.lon <= -64) & (stack_t2m.lat >= -57) & (stack_t2m.lat <= -40), drop=True)\n",
    "stack_t2m_max = stack_t2m.resample(time='1D').max()\n",
    "stack_t2m_min = stack_t2m.resample(time='1D').min()\n",
    "stack_t2m_min = (stack_t2m_min-273.15).round(2)\n",
    "stack_t2m_max = (stack_t2m_max-273.15).round(2)\n",
    "stack_t2m_max.to_netcdf(\"Temperature/T2M_max_ERA5L_1950_2021d.nc\")\n",
    "stack_t2m_min.to_netcdf(\"Temperature/T2M_min_ERA5L_1950_2021d.nc\")\n",
    "\n",
    "dict_ws  = {'longitude':'lon', 'latitude':'lat'}\n",
    "factor      = (2/10)**0.25 #C orrection from 10m to 2m\n",
    "stack_ws    = xr.open_mfdataset(os.path.join(local + \"/ERA5_LAND/Hourly/WS_ERA5L*.nc\"), concat_dim='time', combine='nested', chunks =\"auto\").rename(dict_ws) \n",
    "stack_ws    = stack_ws.where((stack_ws.lon >= -79) & (stack_ws.lon <= -64) & (stack_ws.lat >= -57) & (stack_ws.lat <= -40), drop=True).sortby(\"time\")\n",
    "stack_ws[\"ws\"]= (stack_ws.u10**2 + stack_ws.v10**2)**0.5\n",
    "stack_ws[\"ws\"] = stack_ws.ws*factor\n",
    "stack_ws = stack_ws[\"ws\"].resample(time='1D').mean()\n",
    "stack_ws.to_netcdf(\"Wind_speed/WS_ERA5L_1950_2021d.nc\")\n",
    "\n",
    "dict_hr   = {'longitude':'lon', 'latitude':'lat'}\n",
    "stack_d2m = xr.open_mfdataset(os.path.join(local + \"/ERA5_LAND/Hourly/T2Md*.nc\"), concat_dim='time', combine='nested', chunks =\"auto\")-273.15\n",
    "stack_t2m = xr.open_mfdataset(os.path.join(local + \"/ERA5_LAND/Hourly/T2M*.nc\"), concat_dim='time', combine='nested', chunks =\"auto\")-273.15\n",
    "stack_rh  = xr.merge([stack_d2m, stack_d2m]).rename(dict_hr) \n",
    "stack_rh  = stack_rh.where((stack_rh.lon >= -79) & (stack_rh.lon <= -64) & (stack_rh.lat >= -57) & (stack_rh.lat <= -40), drop=True).sortby(\"time\")\n",
    "stack_rh[\"hr\"] = exp((17.625*stack_rh.d2m)/(243.04+stack_rh.d2m)) / exp((17.625*stack_rh.t2m)/(243.04+stack_rh.t2m))\n",
    "stack_rh = stack_rh[\"hr\"].resample(time='1D').mean()\n",
    "stack_rh.to_netcdf(\"Relative_humidity/RH_ERA5L_1950_2021d.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e383d-1ad3-4d6c-a68d-42766932ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_cr2met.pp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ae34f-47ab-4005-b781-259868a7c024",
   "metadata": {},
   "source": [
    "## MERRA2 (ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76053c3e-d2e9-4276-8513-d0bd4b1c1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly data \n",
    "dict_pp   = {'TPRECMAX':'pp'}\n",
    "stack_pp  = xr.open_mfdataset(os.path.join(local + \"/MERRA2/MERRA2_*.nc4\"), concat_dim='time', combine='nested', chunks =\"auto\").rename(dict_pp)[[\"pp\"]]  \n",
    "stack_pp  = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "months  = xr.DataArray(days.repeat(2021-1980+1), coords=[stack_pp.time], name='month_length')\n",
    "stack_pp  = (stack_pp*months*86400).astype(\"int32\")\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_MERRA2_1980_2021m.nc\")                              \n",
    "\n",
    "dict_t2m  = {'T2MMEAN':'t2m'}\n",
    "stack_t2m = xr.open_mfdataset(os.path.join(local + \"/MERRA2/MERRA2_*.nc4\"), combine='by_coords', chunks =\"auto\").rename(dict_t2m)[[\"t2m\"]]\n",
    "stack_t2m = stack_t2m.where((stack_t2m.lon >= -79) & (stack_t2m.lon <= -64) & (stack_t2m.lat >= -57) & (stack_t2m.lat <= -40), drop=True)\n",
    "stack_t2m = (stack_t2m-273.15).round(2)\n",
    "stack_t2m.to_netcdf(\"Temperature/T2M_MERRA2_1980_2021m.nc\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe96cab-57cf-47c8-ba9b-43e7cddd1138",
   "metadata": {},
   "source": [
    "## CSFR (ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43817623-1eb4-4f1a-b46c-f3b820b17d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Mean (4 per day) of 6-hour Accumulation\n",
    "dict_pp  = {'A_PCP_L1_AccumAvg':'pp'}\n",
    "stack_pp  = xr.open_mfdataset(os.path.join(local + \"/CSFR/PP/*.nc\"), concat_dim='time', combine='nested').sortby(\"time\").rename(dict_pp)[[\"pp\"]]\n",
    "stack_pp.coords['lon'] = (stack_pp.coords['lon'] + 180) % 360 - 180\n",
    "stack_pp = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "stack_pp[\"time\"] = pd.date_range(start='1979/01/01', end='2019/12/01', freq='MS')  \n",
    "months  = xr.DataArray(days.repeat(2019-1979+1), coords=[stack_pp.time], name='month_length')\n",
    "stack_pp  = (stack_pp*months*4).astype(\"int32\")\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_CSFR_1979_2019m.nc\", encoding = encode_pp)\n",
    "\n",
    "# Monthly Mean (4 per day) of 6-hour Accumulation\n",
    "dict_t2m  = {'TMP_L103_Avg':'t2m'}\n",
    "stack_t2m = xr.open_mfdataset(os.path.join(local + \"/CSFR/T2M/*.nc\"), concat_dim='time', combine='nested').sortby(\"time\").rename(dict_t2m)[[\"t2m\"]]\n",
    "stack_t2m.coords['lon'] = (stack_t2m.coords['lon'] + 180) % 360 - 180\n",
    "stack_t2m = stack_t2m.where((stack_t2m.lon >= -79) & (stack_t2m.lon <= -64) & (stack_t2m.lat >= -57) & (stack_t2m.lat <= -40), drop=True)\n",
    "stack_t2m[\"time\"] = pd.date_range(start='1979/01/01', end='2019/12/01', freq='MS') \n",
    "stack_t2m = (stack_t2m-273.15).round(2)                  \n",
    "stack_t2m.to_netcdf(\"Temperature/T2M_CSFR_1979_2019m.nc\", encoding = encode_t2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5ee42-c20f-48f9-b813-48d00bb9a535",
   "metadata": {},
   "source": [
    "## REGCR2: RegCM4-CR2 (ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a335d5e-6930-424b-b7b2-f0b90f4c0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pp  = {'pr':'pp'}\n",
    "stack_pp = xr.open_mfdataset(os.path.join(local + \"/REGCR2/pr_*.nc\"), combine='by_coords').rename(dict_pp).sortby(\"time\")[[\"pp\"]]\n",
    "stack_pp = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "stack_pp[\"time\"] = pd.date_range(start='1980/01/01', end='2015/12/01', freq='MS')  \n",
    "months   = xr.DataArray(days.repeat(2015-1980+1), coords=[stack_pp.time], name='month_length')\n",
    "stack_pp = (stack_pp*months*86400).astype(\"int32\")\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_REGCR2_1980_2015m.nc\", encoding = encode_pp)\n",
    "\n",
    "dict_t2m  = {'tas':'t2m'}\n",
    "stack_t2m = xr.open_mfdataset(os.path.join(local + \"/REGCR2/tas_*.nc\"), combine='by_coords').rename(dict_t2m).sortby(\"time\")[\"t2m\"] \n",
    "stack_t2m = stack_t2m.where((stack_t2m.lon >= -79) & (stack_t2m.lon <= -64) & (stack_t2m.lat >= -57) & (stack_t2m.lat <= -40), drop=True)\n",
    "stack_t2m[\"time\"] = pd.date_range(start='1980/01/01', end='2015/12/01', freq='MS') \n",
    "stack_t2m = (stack_t2m-273.15).round(2)\n",
    "stack_t2m.to_netcdf(\"Temperature/T2M_REGCR2_1980_2015m.nc\", encoding = encode_t2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4a867-9460-4ba8-90f0-71cf4358212d",
   "metadata": {},
   "source": [
    "## MSWEP v2.8 (ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150fe5d-7a52-434d-ac81-aa9527aa7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily time step\n",
    "dict_pp  = {'precipitation':'pp'}\n",
    "stack_pp = xr.open_mfdataset(os.path.join(local + \"/MSWEP/Daily/*.nc\"), combine='by_coords', chunks =\"auto\", parallel = True).rename(dict_pp)  \n",
    "stack_pp = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_MSWEPv28_1979_2020d.nc\")\n",
    "\n",
    "#From daily to monthly\n",
    "stack_pp = xr.open_mfdataset(os.path.join(local + \"/MSWEP/Monthly/*.nc\"), combine='by_coords', chunks =\"auto\", parallel = True).rename(dict_pp)  \n",
    "stack_pp = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "stack_pp = stack_pp.astype(\"int32\")\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_MSWEPv28_1979_2020m.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae73419-588f-483a-9644-86b9092e2740",
   "metadata": {},
   "source": [
    "## CR2MET v2.0 (ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7718142a-aa14-4bcc-9a48-f7130f1b3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily timestep\n",
    "dict_pp   = {'pr':'pp'}\n",
    "stack_pp  = xr.open_dataset(os.path.join(local + \"/CR2MET/PP_CR2METv2_1979_2020d.nc\"), chunks =\"auto\")[[\"pr\"]].rename(dict_pp)\n",
    "stack_pp  = stack_pp.where((stack_pp.lon >= -79) & (stack_pp.lon <= -64) & (stack_pp.lat >= -57) & (stack_pp.lat <= -40), drop=True)\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_CR2MET_1979_2020d.nc\")\n",
    "\n",
    "stack_t2m_max = xr.open_dataset(os.path.join(local + \"/CR2MET/T2M_MAX_CR2METv2_1979_2020d.nc\"), chunks =\"auto\")\n",
    "stack_t2m_max = stack_t2m_max.where((stack_t2m_max.lon >= -79) & (stack_t2m_max.lon <= -64) & (stack_t2m_max.lat >= -57) & (stack_t2m_max.lat <= -40), drop=True)               \n",
    "stack_t2m_max.to_netcdf(\"Temperature/T2M_max_CR2MET_1979_2020d.nc\")                      \n",
    "\n",
    "stack_t2m_min = xr.open_dataset(os.path.join(local + \"/CR2MET/T2M_MIN_CR2METv2_1979_2020d.nc\"), chunks =\"auto\")\n",
    "stack_t2m_min = stack_t2m_min.where((stack_t2m_min.lon >= -79) & (stack_t2m_min.lon <= -64) & (stack_t2m_min.lat >= -57) & (stack_t2m_min.lat <= -40), drop=True)                               \n",
    "stack_t2m_min.to_netcdf(\"Temperature/T2M_min_CR2MET_1979_2020d.nc\")\n",
    "\n",
    "# To monthly timestep \n",
    "stack_pp       = stack_pp.resample(time='MS').sum()    \n",
    "stack_t2m_max  = stack_t2m_max.resample(time='MS').mean()    \n",
    "stack_t2m_min  = stack_t2m_min.resample(time='MS').mean()\n",
    "stack_t2m      = (stack_t2m_max[\"tmax\"]+stack_t2m_min[\"tmin\"])/2 # Just the mean of the maximum and minimum\n",
    "stack_t2m = stack_t2m.to_dataset(name = \"t2m\")\n",
    "\n",
    "stack_pp.to_netcdf(\"Precipitation/PP_CR2MET_1979_2020m.nc\")\n",
    "stack_t2m.to_netcdf(\"Temperature/T2M_CR2MET_1979_2020m.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a4710-c007-48e1-a8ca-660c9f63d96a",
   "metadata": {},
   "source": [
    "## GLEAM v3.6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb24c4ca-d71b-4a3c-b5f0-efa4ed0ccfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rooda/miniconda3/envs/climate/lib/python3.9/site-packages/xarray/core/indexing.py:1234: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  value = value[(slice(None),) * axis + (subkey,)]\n",
      "/tmp/ipykernel_21329/146839499.py:17: SerializationWarning: saving variable pet with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  pet_stack.to_netcdf(\"Evapotranspiration/PET_GLEAM36a_1980_2021m.nc\", encoding = {\"pet\": {\"zlib\": True, \"complevel\": 9, \"dtype\": \"int16\"}})\n"
     ]
    }
   ],
   "source": [
    "# Daily timestep\n",
    "pet_stack = xr.open_mfdataset(os.path.join(local + \"/GLEAM/Daily/Ep_*.nc\"), combine='by_coords', chunks =\"auto\").rename({'Ep':'pet'})\n",
    "pet_stack = pet_stack.where((pet_stack.lon >= -79) & (pet_stack.lon <= -64) & (pet_stack.lat >= -57) & (pet_stack.lat <= -40), drop=True)\n",
    "pet_stack = pet_stack[\"pet\"].where(pet_stack != 0)\n",
    "pet_stack = pet_stack.interpolate_na(dim=\"lon\", method=\"linear\", limit=1)\n",
    "pet_stack = pet_stack.round(2)\n",
    "pet_stack.lon.attrs['long_name'] = 'longitude'\n",
    "pet_stack.lat.attrs[\"long_name\"] = \"latitude\"\n",
    "pet_stack.to_netcdf(\"Evapotranspiration/PET_GLEAM36a_1980_2021d.nc\", encoding = {\"pet\": {\"zlib\": True, \"complevel\": 9, \"dtype\": \"float32\"}})\n",
    "\n",
    "# Monthly timestep\n",
    "pet_stack = pet_stack.resample(time='MS').sum()  # to monthly timestep\n",
    "pet_stack = pet_stack.where(pet_stack != 0)\n",
    "pet_stack = pet_stack.round(0)\n",
    "pet_stack.to_netcdf(\"Evapotranspiration/PET_GLEAM36a_1980_2021m.nc\", encoding = {\"pet\": {\"zlib\": True, \"complevel\": 9, \"dtype\": \"int16\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd15e4-124c-4768-a962-34b8229a9982",
   "metadata": {},
   "source": [
    "## WATER BALANCE III & IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dd6f5d-0ebf-45fb-b3bc-bea5013f1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bh3  = {'dim_lon':'lon', 'dim_lat':'lat', 'dim_time':'time'} # monthly averaged reanalysis (ok)\n",
    "bh3_stack = xr.open_dataset(os.path.join(local + \"/DGA_BH/BH3/netcdf/1_Historico/regionalizacion_1979_2015.nc\")).rename(dict_bh3)\n",
    "bh3_stack = bh3_stack.assign_coords(time = pd.date_range(start='1979/01/01', end='2015/12/01', freq='MS'))\n",
    "bh3_stack = bh3_stack.assign_coords(lon  = bh3_stack.lon)\n",
    "bh3_stack = bh3_stack.assign_coords(lat  = bh3_stack.lat)\n",
    "bh3_stack = bh3_stack.transpose(\"time\", \"lat\", \"lon\")\n",
    "bh3_stack = bh3_stack.where((bh3_stack.lon >= -75) & (bh3_stack.lon <= -71) & (bh3_stack.lat >= -45.8) & (bh3_stack.lat <= -40), drop=True)\n",
    "bh3_stack = bh3_stack.sel(time = slice(\"1985-01-01\", \"2016-01-01\"))\n",
    "bh3_stack = bh3_stack[[\"pr\", \"ET\", \"PET\"]].resample(time='1Y').sum()\n",
    "bh3_stack = bh3_stack.mean(\"time\")\n",
    "bh3_stack = bh3_stack.where(bh3_stack.pr != 0)\n",
    "bh3_stack[\"ET\"] = bh3_stack.ET*30\n",
    "bh3_stack[\"PET\"] = bh3_stack.PET*30\n",
    "\n",
    "bh4_stack_pp  = xr.open_dataset(os.path.join(local + \"/DGA_BH/BH4/Archivos_raster/BH_85-15/Forzantes/1_Historico/pr_Anual_LatLon.tif\"))\n",
    "bh4_stack_pet = xr.open_dataset(os.path.join(local + \"/DGA_BH/BH4/Archivos_raster/BH_85-15/VIC/1_Historico/pet_Anual_LatLon.tif\"))\n",
    "bh4_stack_et  = xr.open_dataset(os.path.join(local + \"/DGA_BH/BH4/Archivos_raster/BH_85-15/VIC/1_Historico/et_Anual_LatLon.tif\"))\n",
    "bh4_stack_pp  = bh4_stack_pp.sel(band=1, drop=True).drop(\"spatial_ref\").rename({'x':'lon',  'y':'lat', 'band_data':'pr'})\n",
    "bh4_stack_pet = bh4_stack_pet.sel(band=1, drop=True).drop(\"spatial_ref\").rename({'x':'lon', 'y':'lat', 'band_data':'PET'})\n",
    "bh4_stack_et  = bh4_stack_et.sel(band=1, drop=True).drop(\"spatial_ref\").rename({'x':'lon',  'y':'lat', 'band_data':'ET'})\n",
    "\n",
    "bh4_stack_pp  = bh4_stack_pp.pr.combine_first(bh3_stack.pr).rename({'lon':'x',  'lat':'y'})\n",
    "bh4_stack_pet = bh4_stack_pet.PET.combine_first(bh3_stack.PET).rename({'lon':'x',  'lat':'y'})\n",
    "bh4_stack_et  = bh4_stack_et.ET.combine_first(bh3_stack.ET).rename({'lon':'x',  'lat':'y'})\n",
    "bh4_stack_pp.rio.to_raster(\"Precipitation/PP_WB_DGA_1985_2015.tif\")\n",
    "bh4_stack_pet.rio.to_raster(\"Evapotranspiration/PET_WB_DGA_1985_2015.tif\")\n",
    "bh4_stack_et.rio.to_raster(\"Evapotranspiration/ET_WB_DGA_1985_2015.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "725755d9-4670-4814-9fc8-72d6098c3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/rooda/Dropbox/Patagonia/Data/Temperature/') \n",
    "\n",
    "t2m_pmet[\"t2m\"]   = (xr.open_dataset(\"Tmax_PMET_1980_2020d.nc\").Tmax + xr.open_dataset(\"Tmin_PMET_1980_2020d.nc\").Tmin)/2\n",
    "t2m_pmet.to_netcdf(\"Tavg_PMET_1980_2020d.nc\")\n",
    "\n",
    "t2m_cr2met[\"t2m\"] = (xr.open_dataset(\"Tmax_CR2MET_1979_2020d.nc\").tmax + xr.open_dataset(\"Tmin_CR2MET_1979_2020d.nc\").tmin)/2\n",
    "t2m_cr2met.to_netcdf(\"Tavg_CR2MET_1979_2020d.nc\")\n",
    "\n",
    "t2m_era5d[\"t2m\"]  = (xr.open_dataset(\"Tmax_ERA5_hr_1980_2020d.nc\").tmax + xr.open_dataset(\"Tmin_ERA5_hr_1980_2020d.nc\").tmin)/2\n",
    "t2m_era5d.to_netcdf(\"Tavg_ERA5_hr_1980_2020d.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d99b8-edbb-49aa-91c2-566a55be7ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
